{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens : 38784\n",
      "\n",
      " ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import tiktoken\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4o-mini\") \n",
    "\n",
    "##change everytime\n",
    "extracted_raw_file = Path(r\"work_on_minutes\\acta_3_octubre_2023\\extracted_text_03_10_23_clean_vers_001.txt\")\n",
    "\n",
    "text_content = []\n",
    "\n",
    "with open(extracted_raw_file, \"r\", encoding=\"utf-8\") as text_file:\n",
    "    text_full = text_file.read()\n",
    "    \n",
    "    # Count the number of tokens    \n",
    "    text_tokens = encoding.encode(text_full)\n",
    "    num_tokens = len(text_tokens)\n",
    "    print(f\"Number of tokens : {num_tokens}\")\n",
    "\n",
    "    text_content.append(text_full) #save for future processing\n",
    "     \n",
    "    print(\"\\n ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## max input tokens 128K \n",
    "# if needed, for a long document, it is going to be necessary to break the document in pieces and make a recursive summarization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Engineering 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#token encoding for the instruction\n",
    "\n",
    "# Load the encoding for the specific model you're using\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4o-mini\")    \n",
    "\n",
    "# Instruction text\n",
    "instruction = f\"Has un resumen de una minuta de reunión de un gobierno local.\\\n",
    "La intención de este ejercicio es proveer al ciudadano común con información relevante sobre el desempeño de su gobierno local. \\\n",
    "Instrucciones especificas: \\\n",
    "- Enfatiza los problemas, peticiones y soluciones o acuerdos que se llegan \\\n",
    "- Indica los nombres de las personas que participan cuando sea necesario.\\\n",
    "- Indica datos concretos \\\n",
    "- No emitas juicios de valor, manten neutralidad\\\n",
    "- Identifica fechas\\\n",
    "- Identifica los temas que se trataron.\\\n",
    "- Verifica con cuidado al final cuantas personas asistieron a la sesion\\\n",
    "\"\n",
    "\n",
    "# Encode the text\n",
    "instruction_tokens = encoding.encode(instruction)\n",
    "\n",
    "# Count the number of tokens\n",
    "num_tokens = len(instruction_tokens)\n",
    "\n",
    "print(f\"Number of tokens: {num_tokens}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Engineering 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 164\n"
     ]
    }
   ],
   "source": [
    "#token encoding for the instruction\n",
    "\n",
    "# Load the encoding for the specific model you're using\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4o-mini\")    \n",
    "\n",
    "# Instruction text\n",
    "instruction = (\n",
    "    \"Has un resumen de una minuta de reunión de un gobierno local con las siguientes instrucciones:\"\n",
    "    \"- Enfatiza los problemas, peticiones y soluciones o acuerdos que se llegan \"\n",
    "    \"- Indica los nombres de las personas que participan cuando sea necesario.\"\n",
    "    \"- Indica datos concretos \"\n",
    "    \"- No emitas juicios de valor, manten neutralidad\"\n",
    "    \"- Identifica los temas que se trataron.\"\n",
    "    \"- Verifica con cuidado cuantas personas asistieron a la sesion al final del documento \"\n",
    "    \"- Envia el texto con estructura dictionario con pares key-value:\"\n",
    "    \"date : fecha_de_la_minuta\" \n",
    "    \"document_id : acta+numero_del_acta\"\n",
    "    \"text : \"\n",
    "    \"{\"\n",
    "    \"## **Nombre del acta:**  \"\n",
    "    \"## **Fecha:**  \"\n",
    "    \"## **Problemas:** \"\n",
    "    \"## **Peticiones:** \"\n",
    "    \"## **Soluciones o acuerdos:**  \"\n",
    "    \"## **Asistentes:**  \"\n",
    "    \"}\"\n",
    ")\n",
    "\n",
    "# Encode the text\n",
    "instruction_tokens = encoding.encode(instruction)\n",
    "\n",
    "# Count the number of tokens\n",
    "num_tokens = len(instruction_tokens)\n",
    "\n",
    "print(f\"Number of tokens: {num_tokens}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading API key\n",
    "load_dotenv()\n",
    "key_ct = os.environ[\"ct_api_key\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client = OpenAI(api_key = key_ct)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model = \"gpt-4o-mini\",\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\" : instruction},\n",
    "        {\"role\":\"user\", \"content\":text_content[0]},\n",
    "    ],\n",
    "    temperature = 0.6,\n",
    "    max_tokens = 1200,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"date\": \"03 de octubre de 2023\",\n",
      "  \"document_id\": \"acta025\",\n",
      "  \"text\": {\n",
      "    \"Nombre del acta\": \"Acta de la Sesión No. 025 Ordinaria del Concejo Metropolitano de Quito\",\n",
      "    \"Fecha\": \"03 de octubre de 2023\",\n",
      "    \"Problemas\": [\n",
      "      \"Inestabilidad en el funcionamiento de las alarmas comunitarias.\",\n",
      "      \"Retraso en la instalación y puesta en marcha de las alarmas.\",\n",
      "      \"Inseguridad en varios barrios de Quito debido a la falta de alarmas operativas.\"\n",
      "    ],\n",
      "    \"Peticiones\": [\n",
      "      \"Solicitar un plan de prevención y preparación ante el fenómeno de El Niño.\",\n",
      "      \"Exigir responsabilidades administrativas y civiles a funcionarios por la falta de información para la instalación de alarmas.\",\n",
      "      \"Demandar claridad sobre los criterios utilizados para la instalación de alarmas en los barrios.\"\n",
      "    ],\n",
      "    \"Soluciones o acuerdos\": [\n",
      "      \"Aprobar la entrega de menciones de honor a entidades que ayudaron durante los incendios.\",\n",
      "      \"Realizar un seguimiento a la situación de las alarmas comunitarias y su funcionamiento.\",\n",
      "      \"Establecer un plan de seguridad que contemple la instalación y mantenimiento de alarmas y cámaras de seguridad.\"\n",
      "    ],\n",
      "    \"Asistentes\": 21\n",
      "  }\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "#change everytime\n",
    "response_summary_TOTAL_vers001 = response.choices[0].message.content\n",
    "print(response_summary_TOTAL_vers001)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting to files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting to .txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#change everytime\n",
    "with open(r\"work_on_minutes\\acta_3_octubre_2023\\response_summary_TOTAL_vers001.txt\", \"w\", encoding=\"utf-8\") as text_file:\n",
    " \n",
    "    text_file.write(response_summary_TOTAL_vers001)  # Write the block text to the file, with spacing between blocks\n",
    "\n",
    "print(\"Text extraction completed and saved'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting to .md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#change everytime\n",
    "with open(r\"C:\\Users\\herms\\Desktop\\Civic_Tech_Research_Project\\PreliminarWork\\preprocessing\\work_on_minutes\\acta_26_abril_2019\\summary_26_04_19\\response_summary_TOTAL_vers002.md\", \"w\", encoding=\"utf-8\") as text_file:\n",
    " \n",
    "    text_file.write(response_summary_TOTAL_vers002)  # Write the block text to the file, with spacing between blocks\n",
    "\n",
    "print(\"Text extraction completed and saved to 'response_summary_TOTAL_vers002'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting to .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text extraction completed and saved as JSON.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# Convert the text to a JSON-compatible format\n",
    "\n",
    "data = {\n",
    "    \"text\": response_summary_TOTAL_vers001\n",
    "}\n",
    "\n",
    "# Write the JSON data to a new file\n",
    "with open(r\"work_on_minutes\\acta_3_octubre_2023\\response_summary_TOTAL_vers001.json\", \"w\", encoding=\"utf-8\") as json_file:\n",
    "    json.dump(data, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"Text extraction completed and saved as JSON.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
