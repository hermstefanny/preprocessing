{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens of chunk_0.txt: 5200\n",
      "\n",
      " ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Number of tokens of chunk_1.txt: 4194\n",
      "\n",
      " ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Number of tokens of chunk_2.txt: 4410\n",
      "\n",
      " ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Number of tokens of chunk_3.txt: 4725\n",
      "\n",
      " ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Number of tokens of chunk_4.txt: 578\n",
      "\n",
      " ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import tiktoken\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4\") \n",
    "\n",
    "directory = Path(r'C:\\Users\\herms\\Desktop\\Civic_Tech_Research_Project\\PreliminarWork\\preprocessing\\acta_4_febrero_2019\\chunks_texts')\n",
    "\n",
    "text_content =[]\n",
    "# Iterate over all .txt files in the directory\n",
    "for file_path in directory.glob('*.txt'):\n",
    "    # Open and read the file\n",
    "    with file_path.open('r', encoding=\"utf8\") as file:\n",
    "        text_file = file.read()\n",
    "        # Count the number of tokens    \n",
    "        instruction_tokens = encoding.encode(text_file)\n",
    "        num_tokens = len(instruction_tokens)\n",
    "        print(f\"Number of tokens of {file_path.name}: {num_tokens}\")\n",
    "\n",
    "        text_content.append(text_file) #save for future processing\n",
    "     \n",
    "        print(\"\\n ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 94\n"
     ]
    }
   ],
   "source": [
    "#token encoding for the instruction\n",
    "\n",
    "# Load the encoding for the specific model you're using\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4\")    \n",
    "\n",
    "# Instruction text\n",
    "instruction = f\"Has un resumen de entre 400 y 500 palabras de una minuta de reunión de un gobierno local latinoamericano.\\\n",
    "- Enfatiza los problemas, peticiones y soluciones o acuerdos que se llegan \\\n",
    "- Indica los nombres de las personas que participan.\\\n",
    "- Indica datos concretos \\\n",
    "- No emitas juicios de valor, manten neutralidad\\\n",
    "- Identifica fechas\\\n",
    "- Identifica los temas que se trataron.\"\n",
    "\n",
    "# Encode the text\n",
    "instruction_tokens = encoding.encode(instruction)\n",
    "\n",
    "# Count the number of tokens\n",
    "num_tokens = len(instruction_tokens)\n",
    "\n",
    "print(f\"Number of tokens: {num_tokens}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "# loading API key\n",
    "load_dotenv()\n",
    "key_ct = os.environ[\"ct_api_key\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: El 4 de febrero de 2019, el Concejo Metropolitano de Quito, presidido por el Dr. Mauricio Rodas Espinel, celebró una sesión extraordinaria con la asistencia de 22 concejales. La sesión se centró en el segundo debate del proyecto de Ordenanza Metropolitana Reformatoria a la Ordenanza Metropolitana No. 232, que establece el Régimen Administrativo para la prestación del servicio de taxi en el Distrito Metropolitano de Quito.\n",
      "\n",
      "El Secretario de Movilidad, Ing. Alfredo León, presentó un informe técnico que analizó el estudio para determinar la oferta y demanda del servicio de taxi en Quito. El informe concluyó que el número actual de 8.693 cupos sería insuficiente para equilibrar el mercado. Se sugirió que la Agencia Metropolitana de Tránsito (AMT) había identificado un total de 12.905 aplicantes idóneos y que el número final de cupos asignados sería menor a este número, pero solo se conocería al finalizar el proceso.\n",
      "\n",
      "El informe técnico también destacó varios factores exógenos que afectaron el resultado del estudio, incluyendo el crecimiento poblacional y demográfico de Quito, la migración interna y externa, la necesidad de empleo y la situación jurídica actual.\n",
      "\n",
      "El Concejal Dr. Pedro Freire expresó su apoyo a pesar de no estar de acuerdo con el proceso de subsanación, argumentando que los concejales están obligados a solucionar los problemas de la ciudadanía. Freire pidió un informe jurídico del Procurador para aclarar las dudas en relación con la consultoría contratada para determinar el número de cupos, que costó casi $250.000 dólares.\n",
      "\n",
      "La sesión concluyó sin una decisión final, pero con un compromiso de continuar el debate y buscar una solución equilibrada para el servicio de taxi en Quito.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "client = OpenAI(api_key = key_ct)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model = \"gpt-4\",\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\" : instruction},\n",
    "        {\"role\":\"user\", \"content\":text_content[0]},\n",
    "    ],\n",
    "    temperature = 0.5,\n",
    "    max_tokens = 800,\n",
    ")\n",
    "\n",
    "response_summary = response.choices[0].message.content\n",
    "print(\"Summary:\", response_summary)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
