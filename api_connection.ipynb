{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens : 16787\n",
      "\n",
      " ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import tiktoken\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4o-mini\") \n",
    "\n",
    "extracted_file = Path(r'C:\\Users\\herms\\Desktop\\Civic_Tech_Research_Project\\PreliminarWork\\preprocessing\\extracted_text_no_headers_footers_clean_vers_001.txt')\n",
    "\n",
    "text_content = []\n",
    "\n",
    "with open(\"extracted_text_no_headers_footers_clean_vers_001.txt\", \"r\", encoding=\"utf-8\") as text_file:\n",
    "    text_full = text_file.read()\n",
    "\n",
    "    \n",
    "    # Count the number of tokens    \n",
    "    instruction_tokens = encoding.encode(text_full)\n",
    "    num_tokens = len(instruction_tokens)\n",
    "    print(f\"Number of tokens : {num_tokens}\")\n",
    "\n",
    "    text_content.append(text_full) #save for future processing\n",
    "     \n",
    "    print(\"\\n ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## if needed, for a long document, it is going to be necessary to break the document in pieces and make a recursive summarization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 101\n"
     ]
    }
   ],
   "source": [
    "#token encoding for the instruction\n",
    "\n",
    "# Load the encoding for the specific model you're using\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4o-mini\")    \n",
    "\n",
    "# Instruction text\n",
    "instruction = f\"Has un resumen de una minuta de reunión de un gobierno local.\\\n",
    "La intención de este ejercicio es proveer al ciudadano común con información relevante sobre el desempeño de su gobierno local. \\\n",
    "Instrucciones especificas: \\\n",
    "- Enfatiza los problemas, peticiones y soluciones o acuerdos que se llegan \\\n",
    "- Indica los nombres de las personas que participan cuando sea necesario.\\\n",
    "- Indica datos concretos \\\n",
    "- No emitas juicios de valor, manten neutralidad\\\n",
    "- Identifica fechas\\\n",
    "- Identifica los temas que se trataron.\"\n",
    "\n",
    "# Encode the text\n",
    "instruction_tokens = encoding.encode(instruction)\n",
    "\n",
    "# Count the number of tokens\n",
    "num_tokens = len(instruction_tokens)\n",
    "\n",
    "print(f\"Number of tokens: {num_tokens}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading API key\n",
    "load_dotenv()\n",
    "key_ct = os.environ[\"ct_api_key\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: **Minuta de Reunión - Concejo Metropolitano de Quito**\n",
      "\n",
      "**Fecha:** 04 de febrero de 2019  \n",
      "**Hora de inicio:** 11:35 AM  \n",
      "**Hora de finalización:** 12:43 PM  \n",
      "**Asistentes:** 18 concejales y el Alcalde Metropolitano, Dr. Mauricio Rodas Espinel.\n",
      "\n",
      "### Temas Tratados:\n",
      "\n",
      "1. **Segundo Debate del Proyecto de Ordenanza Metropolitana Reformatoria a la Ordenanza No. 232.**\n",
      "   - Se busca regular la prestación del servicio de taxi en el Distrito Metropolitano de Quito.\n",
      "\n",
      "### Problemas Identificados:\n",
      "- **Cupos insuficientes:** El estudio previo determinó que hay 8,693 cupos, mientras que 12,905 aplicantes fueron calificados como idóneos.\n",
      "- **Crecimiento poblacional y demanda:** Se ha incrementado la necesidad del servicio de taxi debido a la migración y el crecimiento demográfico.\n",
      "\n",
      "### Peticiones Realizadas:\n",
      "- **Claridad Jurídica:** Se solicitó al Procurador Metropolitano, Dr. Gianni Frixone, que aclare si la decisión del Concejo está enmarcada en la legalidad y si existen riesgos jurídicos para los concejales.\n",
      "- **Seguridad en la base de datos de aplicantes:** La concejala Ivone Von Lippke pidió medidas para evitar la alteración de datos de los 12,905 aplicantes.\n",
      "\n",
      "### Soluciones y Acuerdos:\n",
      "- **Aprobación de la Ordenanza:** Se aprobó en segundo y definitivo debate la Ordenanza que permitirá la asignación de hasta 12,905 cupos, con la condición de que solo aquellos que cumplan con los requisitos recibirán los permisos.\n",
      "- **Incorporación de Observaciones:** Se incluyeron propuestas de diferentes concejales para garantizar la claridad en la entrega de informes de constitución jurídica y mantener la protección de los idóneos durante el proceso.\n",
      "- **Plazo para el Proceso:** Se estableció un plazo máximo de 90 días para la entrega de informes y resolución de solicitudes.\n",
      "\n",
      "### Resultados de la Votación:\n",
      "- **A favor:** 19 votos\n",
      "- **En contra:** 0\n",
      "- **Blanco:** 0\n",
      "- **Ausente:** 3\n",
      "\n",
      "**Conclusión:** El Concejo Metropolitano aprobó la reforma a la Ordenanza que regula el servicio de taxis, buscando una solución a la necesidad de regulación en el sector, y asegurando la transparencia y legalidad del proceso. \n",
      "\n",
      "**Registro de asistencia finalizado.**\n"
     ]
    }
   ],
   "source": [
    "\n",
    "client = OpenAI(api_key = key_ct)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model = \"gpt-4o-mini\",\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\" : instruction},\n",
    "        {\"role\":\"user\", \"content\":text_content[0]},\n",
    "    ],\n",
    "    temperature = 0.7,\n",
    "    max_tokens = 5000,\n",
    ")\n",
    "\n",
    "response_summary_TOTAL_vers3 = response.choices[0].message.content\n",
    "print(\"Summary:\", response_summary_TOTAL_vers3)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text extraction completed and saved to 'response_summary_TOTAL_vers4'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with open(\"response_summary_TOTAL_vers4.txt\", \"w\", encoding=\"utf-8\") as text_file:\n",
    " \n",
    "    text_file.write(response_summary_TOTAL_vers3)  # Write the block text to the file, with spacing between blocks\n",
    "\n",
    "print(\"Text extraction completed and saved to 'response_summary_TOTAL_vers4'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
