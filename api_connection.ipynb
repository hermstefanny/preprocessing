{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens : 42887\n",
      "\n",
      " ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import tiktoken\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4o-mini\") \n",
    "\n",
    "##CHANGE EVERYTIME THE PATH\n",
    "extracted_raw_file = Path(r\"C:\\Users\\herms\\Desktop\\Civic_Tech_Research_Project\\PreliminarWork\\preprocessing\\data\\2024\\acta_02_04_2024\\extracted_text_02_04_24_clean_vers_001.txt\")\n",
    "\n",
    "text_content = []\n",
    "\n",
    "with open(extracted_raw_file, \"r\", encoding=\"utf-8\") as text_file:\n",
    "    text_full = text_file.read()\n",
    "    \n",
    "    # Count the number of tokens    \n",
    "    text_tokens = encoding.encode(text_full)\n",
    "    num_tokens = len(text_tokens)\n",
    "    print(f\"Number of tokens : {num_tokens}\")\n",
    "\n",
    "    text_content.append(text_full) #save for future processing\n",
    "     \n",
    "    print(\"\\n ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## max input tokens 128K \n",
    "# if needed, for a long document, it is going to be necessary to break the document in pieces and make a recursive summarization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Engineering 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tiktoken' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#token encoding for the instruction\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Load the encoding for the specific model you're using\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m encoding \u001b[38;5;241m=\u001b[39m \u001b[43mtiktoken\u001b[49m\u001b[38;5;241m.\u001b[39mencoding_for_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4o-mini\u001b[39m\u001b[38;5;124m\"\u001b[39m)    \n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Instruction text\u001b[39;00m\n\u001b[0;32m      7\u001b[0m instruction \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHas un resumen de una minuta de reunión de un gobierno local.\u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124mLa intención de este ejercicio es proveer al ciudadano común con información relevante sobre el desempeño de su gobierno local. \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124mInstrucciones especificas: \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124m- Verifica con cuidado al final cuantas personas asistieron a la sesion\u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tiktoken' is not defined"
     ]
    }
   ],
   "source": [
    "#token encoding for the instruction\n",
    "\n",
    "# Load the encoding for the specific model you're using\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4o-mini\")    \n",
    "\n",
    "# Instruction text\n",
    "instruction = f\"Has un resumen de una minuta de reunión de un gobierno local.\\\n",
    "La intención de este ejercicio es proveer al ciudadano común con información relevante sobre el desempeño de su gobierno local. \\\n",
    "Instrucciones especificas: \\\n",
    "- Enfatiza los problemas, peticiones y soluciones o acuerdos que se llegan \\\n",
    "- Indica los nombres de las personas que participan cuando sea necesario.\\\n",
    "- Indica datos concretos \\\n",
    "- No emitas juicios de valor, manten neutralidad\\\n",
    "- Identifica fechas\\\n",
    "- Identifica los temas que se trataron.\\\n",
    "- Verifica con cuidado al final cuantas personas asistieron a la sesion\\\n",
    "\"\n",
    "\n",
    "# Encode the text\n",
    "instruction_tokens = encoding.encode(instruction)\n",
    "\n",
    "# Count the number of tokens\n",
    "num_tokens = len(instruction_tokens)\n",
    "\n",
    "print(f\"Number of tokens: {num_tokens}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Engineering 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 220\n"
     ]
    }
   ],
   "source": [
    "#token encoding for the instruction\n",
    "\n",
    "# Load the encoding for the specific model you're using\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4o-mini\")    \n",
    "\n",
    "# Instruction text\n",
    "instruction = \"\"\"Has un resumen de una minuta de reunión de un gobierno local con las siguientes instrucciones:\n",
    "-  Enfatiza Los principales temas que se hablaron en la sesion, enfatizando los problemas, peticiones y soluciones o acuerdos que se llegan, indicando los nombres de las personas que participan cuando sea necesario.\n",
    "    - Provee datos concretos\n",
    "    - No emitas juicios de valor\n",
    "    - Establece si el acta pertenece a una sesión o a varias sesiones. Menciona solo si es de varias sesiones y especifica las fechas\n",
    "    - Verifica con cuidado cuantas personas asistieron a la sesion\"\n",
    "    - Envia la informacion con la siguiente estructura:\n",
    "     {\n",
    "     \"date\" : \"yyyy-mm-dd\", \n",
    "     \"document_id\" : \"acta_0xx(numero_del_acta)\", \n",
    "     \"act_name\": \"Sesion (nombre y numero de la sesion)\", \n",
    "     \"content:  [\" resumen de la sesion en donde se explique de manera fluida y clara con las instrucciones enviadas arriba\"], \n",
    "    } \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "# Encode the text\n",
    "instruction_tokens = encoding.encode(instruction)\n",
    "\n",
    "# Count the number of tokens\n",
    "num_tokens = len(instruction_tokens)\n",
    "\n",
    "print(f\"Number of tokens: {num_tokens}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading API key\n",
    "load_dotenv()\n",
    "key_ct = os.environ[\"ct_api_key\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client = OpenAI(api_key = key_ct)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model = \"gpt-4o-mini\",\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\" : instruction},\n",
    "        {\"role\":\"user\", \"content\":text_content[0]},\n",
    "    ],\n",
    "    temperature = 0.80,\n",
    "    max_tokens = 1200,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"date\": \"2024-04-02\",\n",
      "  \"document_id\": \"acta_055\",\n",
      "  \"act_name\": \"Sesión Ordinaria de Concejo No. 055\",\n",
      "  \"content\": [\n",
      "    \"En la sesión ordinaria del Concejo Metropolitano de Quito celebrada el 2 de abril de 2024, se abordaron diversos temas. Se verificó el cuórum con la presencia de 14 concejales al inicio, incrementando a 18 durante la sesión. Uno de los temas principales fue la presentación de la 'Agenda Feminista de Quito' expuesta por María de Lourdes Quishpe Pazmiño, Coordinadora de la Plataforma de Mujeres Caminando hacia la Igualdad. Se discutieron problemáticas como la necesidad de un Sistema Integral de Cuidados, el hábitat sostenible y la regularización de barrios, así como la urgencia de atender la violencia de género y la igualdad salarial. Las concejalas y concejales expresaron su apoyo a la agenda y propusieron que sea la Comisión de Igualdad, Género e Inclusión Social quien supervise su implementación.\",\n",
      "    \"Otro tema significativo fue la presentación de la matriz de identificación de placas conmemorativas en obras públicas, donde se identificaron 241 placas que incumplen con la resolución sobre la inclusión de nombres de servidores públicos en estas. El Administrador General, Christian Cruz Rodríguez, explicó que se procederá al retiro de dichas placas.\",\n",
      "    \"Finalmente, se presentó un informe sobre la calidad de alimentos vendidos en el parque La Carolina, donde se analizaron 29 muestras, encontrándose que 19 no cumplían con los parámetros de seguridad alimentaria. La Secretaria de Salud, Marysol Ruilova, expuso que el control de alimentos es parte de las competencias del Municipio en coordinación con el Gobierno Nacional, y se destacó la necesidad de un mayor control sobre el comercio informal. Las intervenciones de los concejales manifestaron preocupaciones sobre la salud pública y la responsabilidad de los comerciantes en el expendio de alimentos.\",\n",
      "    \"Se acordó seguir trabajando en la implementación de la agenda feminista y en las medidas necesarias para mejorar la calidad de los alimentos en el ámbito de la salud pública.\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#change everytime\n",
    "response_summary_TOTAL_vers001 = response.choices[0].message.content\n",
    "print(response_summary_TOTAL_vers001)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract ther markdown labels\n",
    "\n",
    "import re\n",
    "\n",
    "def extract_markdown_content(text):\n",
    "    # Regular expression to find content between triple backticks\n",
    "    pattern = r\"```json(.*?)```\"\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    \n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "\n",
    "response_summary_TOTAL_vers001_formatted = extract_markdown_content(response_summary_TOTAL_vers001)\n",
    "print(response_summary_TOTAL_vers001_formatted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting to files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting to .txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text extraction completed and saved'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#change everytime\n",
    "with open(r\"C:\\Users\\herms\\Desktop\\Civic_Tech_Research_Project\\PreliminarWork\\preprocessing\\data\\2024\\acta_02_04_2024\\response_summary_TOTAL_vers001.json\", \"w\", encoding=\"utf-8\") as text_file:\n",
    " \n",
    "    text_file.write(response_summary_TOTAL_vers001)  # Write the block text to the file, with spacing between blocks\n",
    "    #review the response everytime\n",
    "\n",
    "print(\"Text extraction completed and saved'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting to .md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#change everytime\n",
    "with open(r\"C:\\Users\\herms\\Desktop\\Civic_Tech_Research_Project\\PreliminarWork\\preprocessing\\work_on_minutes\\acta_26_abril_2019\\summary_26_04_19\\response_summary_TOTAL_vers002.md\", \"w\", encoding=\"utf-8\") as text_file:\n",
    " \n",
    "    text_file.write(response_summary_TOTAL_vers002)  # Write the block text to the file, with spacing between blocks\n",
    "\n",
    "print(\"Text extraction completed and saved to 'response_summary_TOTAL_vers002'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting to .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Write the JSON data to a new file\n",
    "with open(r\"work_on_minutes\\acta_05_diciembre_2023\\response_summary_TOTAL_vers002.json\", \"w\", encoding=\"utf-8\") as json_file:\n",
    "    json.dump( response_summary_TOTAL_vers002_formatted, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"Text extraction completed and saved as JSON.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
