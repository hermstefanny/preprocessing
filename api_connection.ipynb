{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens : 23307\n",
      "\n",
      " ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import tiktoken\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4o-mini\") \n",
    "\n",
    "##change everytime\n",
    "extracted_raw_file = Path(r\"C:\\Users\\herms\\Desktop\\Civic_Tech_Research_Project\\PreliminarWork\\preprocessing\\work_on_minutes\\acta_26_abril_2019\\extracted_26_04_19\\extracted_text_nh_nf_26_04_19_clean_vers_001.txt\")\n",
    "\n",
    "text_content = []\n",
    "\n",
    "with open(extracted_raw_file, \"r\", encoding=\"utf-8\") as text_file:\n",
    "    text_full = text_file.read()\n",
    "    \n",
    "    # Count the number of tokens    \n",
    "    instruction_tokens = encoding.encode(text_full)\n",
    "    num_tokens = len(instruction_tokens)\n",
    "    print(f\"Number of tokens : {num_tokens}\")\n",
    "\n",
    "    text_content.append(text_full) #save for future processing\n",
    "     \n",
    "    print(\"\\n ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## max input tokens 128K \n",
    "# if needed, for a long document, it is going to be necessary to break the document in pieces and make a recursive summarization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 124\n"
     ]
    }
   ],
   "source": [
    "#token encoding for the instruction\n",
    "\n",
    "# Load the encoding for the specific model you're using\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4o-mini\")    \n",
    "\n",
    "# Instruction text\n",
    "instruction = f\"Has un resumen de una minuta de reunión de un gobierno local.\\\n",
    "La intención de este ejercicio es proveer al ciudadano común con información relevante sobre el desempeño de su gobierno local. \\\n",
    "Instrucciones especificas: \\\n",
    "- Enfatiza los problemas, peticiones y soluciones o acuerdos que se llegan \\\n",
    "- Indica los nombres de las personas que participan cuando sea necesario.\\\n",
    "- Indica datos concretos \\\n",
    "- No emitas juicios de valor, manten neutralidad\\\n",
    "- Identifica fechas\\\n",
    "- Identifica los temas que se trataron.\\\n",
    "- Verifica con cuidado al final cuantas personas asistieron a la sesion\\\n",
    "\"\n",
    "\n",
    "# Encode the text\n",
    "instruction_tokens = encoding.encode(instruction)\n",
    "\n",
    "# Count the number of tokens\n",
    "num_tokens = len(instruction_tokens)\n",
    "\n",
    "print(f\"Number of tokens: {num_tokens}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading API key\n",
    "load_dotenv()\n",
    "key_ct = os.environ[\"ct_api_key\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client = OpenAI(api_key = key_ct)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model = \"gpt-4o-mini\",\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\" : instruction},\n",
    "        {\"role\":\"user\", \"content\":text_content[0]},\n",
    "    ],\n",
    "    temperature = 0.6,\n",
    "    max_tokens = 1000,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Resumen de la Sesión Extraordinaria del Concejo Metropolitano de Quito\n",
      "\n",
      "**Fecha:** 26 de abril de 2019  \n",
      "**Hora de inicio:** 14:50  \n",
      "**Asistentes:** 11 concejales y el Alcalde, Dr. Mauricio Rodas Espinel.  \n",
      "**Total de asistentes:** 13 personas.\n",
      "\n",
      "## Temas tratados:\n",
      "\n",
      "### 1. Comparecencia de la Gerencia de EMGIRS\n",
      "- **Problema:** El concejal Marco Ponce expresó su preocupación por la ausencia del gerente de EMGIRS en la sesión anterior, lo que considera un desacato a la resolución del Concejo.\n",
      "- **Acuerdo:** El Alcalde se comprometió a incluir la comparecencia del gerente en la próxima sesión ordinaria del Concejo.\n",
      "\n",
      "### 2. Proyecto de Ordenanza sobre Incremento de Pisos\n",
      "- **Descripción:** Se discutió la Ordenanza Metropolitana que regula el incremento de pisos por suelo creado, en proyectos eco-eficientes ubicados en áreas de influencia del Sistema Metropolitano de Transporte y en Zonas Urbanísticas de Asignación Especial (ZUAE).\n",
      "- **Participantes:** La Comisión de Uso de Suelo, con la participación de varios concejales y representantes de gremios, presentó el proyecto.\n",
      "- **Principales puntos del proyecto:**\n",
      "  - Implementación de parámetros obligatorios y optativos relacionados con la eco-eficiencia.\n",
      "  - Propuesta de inversión en infraestructura pública como parte del pago por el incremento de pisos.\n",
      "  - Se establece un sistema de calificación de eco-eficiencia que incluye parámetros de reducción del consumo de agua y energía.\n",
      "- **Acuerdo:** Se aprobó por mayoría (15 votos a favor, 0 en contra) el proyecto de ordenanza en segundo y definitivo debate.\n",
      "\n",
      "### 3. Revisión de Parámetros de Estacionamientos\n",
      "- **Problema:** Se discutió la necesidad de ajustar los requerimientos de estacionamientos en proyectos eco-eficientes.\n",
      "- **Propuesta:** Se sugirió permitir un número máximo de estacionamientos en función de la ubicación de los proyectos respecto a nodos de transporte.\n",
      "- **Acuerdo:** Se acordó mantener un margen del 30% de tolerancia para los BRT y del 15% para el Metro.\n",
      "\n",
      "## Resoluciones:\n",
      "- Se aprobó la Ordenanza Metropolitana sobre el incremento de pisos, con un enfoque en la eco-eficiencia y el desarrollo urbano sostenible.\n",
      "- Se estableció la necesidad de que la Secretaría de Territorio, Hábitat y Vivienda ajuste los parámetros de delimitación de los polígonos de influencia del Metro y BRT en un plazo de 60 días.\n",
      "\n",
      "## Cierre de la sesión:\n",
      "- La sesión fue clausurada a las 16:02 por falta de quórum, después de la discusión del segundo punto del orden del día.\n",
      "\n",
      "## Asistentes:\n",
      "1. Sr. Jorge Albán\n",
      "2. MSc. Soledad Benítez\n",
      "3. Lic. Susana Castañeda\n",
      "4. Inter. Carla Cevallos\n",
      "5. Sra. Monserrate Cevallos\n",
      "6. Sra. Gisela Chalá\n",
      "7. Abg. Miguel Coro\n",
      "8. Sra. Silvia Díaz\n",
      "9. Dr. Pedro Freire\n",
      "10. Abg. Sergio Garnica\n",
      "11. Dr. Mario Granda\n",
      "12. Abg. Mario Guayasamín\n",
      "13. Ing. Anabel Hermosa\n",
      "14. Dra. Renata Moreno\n",
      "15. Ing. Carlos Páez\n",
      "16. Sr. Marco Ponce\n",
      "17. Eco. Luis Reina\n",
      "18. Abg. Renata Salvador\n",
      "19. Lic. Eddy Sánchez\n",
      "20. Sra. Karen Sánchez\n",
      "21. Sra. Ivone Von Lippke\n",
      "22. Dr. Mauricio Rodas Espinel (Alcalde Metropolitano)\n",
      "\n",
      "--- \n",
      "\n",
      "Este resumen proporciona una visión clara de los temas tratados, las preocupaciones planteadas y las decisiones tomadas durante la reunión, lo que permite a los ciudadanos estar informados sobre el desempeño y las acciones de su gobierno local.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#change everytime\n",
    "response_summary_TOTAL_vers005 = response.choices[0].message.content\n",
    "print(response_summary_TOTAL_vers005)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting to .txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text extraction completed and saved'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#change everytime\n",
    "with open(r\"C:\\Users\\herms\\Desktop\\Civic_Tech_Research_Project\\PreliminarWork\\preprocessing\\work_on_minutes\\acta_26_abril_2019\\summary_26_04_19\\response_summary_TOTAL_vers005.txt\", \"w\", encoding=\"utf-8\") as text_file:\n",
    " \n",
    "    text_file.write(response_summary_TOTAL_vers005)  # Write the block text to the file, with spacing between blocks\n",
    "\n",
    "print(\"Text extraction completed and saved'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting to .md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text extraction completed and saved to 'response_summary_TOTAL_vers002'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#change everytime\n",
    "with open(r\"C:\\Users\\herms\\Desktop\\Civic_Tech_Research_Project\\PreliminarWork\\preprocessing\\work_on_minutes\\acta_26_abril_2019\\summary_26_04_19\\response_summary_TOTAL_vers002.md\", \"w\", encoding=\"utf-8\") as text_file:\n",
    " \n",
    "    text_file.write(response_summary_TOTAL_vers002)  # Write the block text to the file, with spacing between blocks\n",
    "\n",
    "print(\"Text extraction completed and saved to 'response_summary_TOTAL_vers002'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
