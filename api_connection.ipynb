{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens of chunk_0.txt: 5200\n",
      "\n",
      " ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Number of tokens of chunk_1.txt: 4194\n",
      "\n",
      " ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Number of tokens of chunk_2.txt: 4410\n",
      "\n",
      " ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Number of tokens of chunk_3.txt: 4725\n",
      "\n",
      " ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Number of tokens of chunk_4.txt: 578\n",
      "\n",
      " ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import tiktoken\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4\") \n",
    "\n",
    "directory = Path(r'C:\\Users\\herms\\Desktop\\Civic_Tech_Research_Project\\PreliminarWork\\preprocessing\\acta_4_febrero_2019\\chunks_texts')\n",
    "\n",
    "text_content =[]\n",
    "# Iterate over all .txt files in the directory\n",
    "for file_path in directory.glob('*.txt'):\n",
    "    # Open and read the file\n",
    "    with file_path.open('r', encoding=\"utf8\") as file:\n",
    "        text_file = file.read()\n",
    "        # Count the number of tokens    \n",
    "        instruction_tokens = encoding.encode(text_file)\n",
    "        num_tokens = len(instruction_tokens)\n",
    "        print(f\"Number of tokens of {file_path.name}: {num_tokens}\")\n",
    "\n",
    "        text_content.append(text_file) #save for future processing\n",
    "     \n",
    "        print(\"\\n ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 156\n"
     ]
    }
   ],
   "source": [
    "#token encoding for the instruction\n",
    "\n",
    "# Load the encoding for the specific model you're using\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4\")    \n",
    "\n",
    "# Instruction text\n",
    "instruction = f\"Vas a hacer un resumen de máximo 500 palabras de una minuta de reunión de un gobierno local latinoamericano.\\\n",
    "Estas son las instrucciones a tener en cuenta para el resumen:\\\n",
    "- Enfatiza los problemas, peticiones y soluciones o acuerdos que se llegan \\\n",
    "- Puedes indicar, cuando sea necesario, quienes son las personas que participan.\\\n",
    "- Indica datos concretos para acompañar la información presentada \\\n",
    "- Es importante que no emitas juicios de valor. Mantén una posición neutral, informando hechos.\\\n",
    "Detalles específicos a tomar en cuenta:\\\n",
    "- Identificar la fecha en que se realizó la reunión.\\\n",
    "- Identificar el tema o los temas que se trataron en la reunion.\"\n",
    "\n",
    "# Encode the text\n",
    "instruction_tokens = encoding.encode(instruction)\n",
    "\n",
    "# Count the number of tokens\n",
    "num_tokens = len(instruction_tokens)\n",
    "\n",
    "print(f\"Number of tokens: {num_tokens}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "# loading API key\n",
    "load_dotenv()\n",
    "key_ct = os.environ[\"ct_api_key\"]\n",
    "print(key_ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: La reunión extraordinaria del Concejo Metropolitano de Quito se llevó a cabo el 4 de febrero de 2019, presidida por el alcalde Mauricio Rodas Espinel. La sesión se centró en el segundo debate del proyecto de Ordenanza Metropolitana Reformatoria a la Ordenanza Metropolitana No. 232, que establece el régimen administrativo para la prestación del servicio de taxi en el Distrito Metropolitano de Quito.\n",
      "\n",
      "El Secretario de Movilidad, Alfredo León, presentó un informe técnico basado en un estudio de oferta y demanda de taxis en la ciudad. El informe sugiere que los 8.693 cupos para taxis serían insuficientes para equilibrar el mercado y propone continuar con el proceso de asignación de cupos hasta llegar a un máximo de 12.905, número definido por la Agencia Metropolitana de Tránsito (AMT) como aplicantes idóneos.\n",
      "\n",
      "El informe técnico también consideró factores exógenos como el crecimiento poblacional, el crecimiento demográfico-urbanístico del distrito, la migración interna a Quito y externa al país, y las condiciones sociales y económicas actuales.\n",
      "\n",
      "El concejal Pedro Freire expresó su apoyo a la propuesta a pesar de no estar de acuerdo con la subsanación inicial. Sin embargo, solicitó un informe jurídico para analizar las posibles consecuencias de no aplicar la consultoría que costó casi $250.000 dólares y que determinó inicialmente los 8.692 cupos para taxis.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "client = OpenAI(api_key = key_ct)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model = \"gpt-4\",\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\" : instruction},\n",
    "        {\"role\":\"user\", \"content\":text_content[0]},\n",
    "    ],\n",
    "    temperature = 0.3,\n",
    "    max_tokens = 400,\n",
    ")\n",
    "\n",
    "for summary in summaries\n",
    "response_summary = response.choices[0].message.content\n",
    "print(\"Summary:\", response_summary)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
